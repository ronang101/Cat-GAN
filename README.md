# Cat Image Generation with GANs

This repository contains a TensorFlow implementation of a Generative Adversarial Network (GAN) trained to generate realistic 64x64 pixel coloured cat images. The project demonstrates the power of GANs in generating lifelike images that can sometimes be indistinguishable from real photos. I created this as a fun and educational project, it served to further my understanding of deep learning, specifically GANs, while providing practical experience in training a model on a home laptop.

## Project Overview

### Purpose
The purpose of this project is to explore the capabilities of Generative Adversarial Networks (GANs) in generating lifelike images and to provide a hands-on experience with deep learning models in order to understand how they are trained and mess around with the training parameters to see what works best.

### Model Performance
The model demonstrates its effectiveness by tricking the user 1 out of every 7 times with its generated images, you can test this yourself using the human_model_tester_game.py. 

### Educational Value
This project includes scripts with thorough comments aimed at helping users understand the underlying architecture and operations of GANs.

## Project Structure

- **cats_training.py**: The main training script for the GAN model. Detailed comments within the script explain the training process, architecture choices, and TensorFlow operations.
- **human_model_tester_game.py**: An interactive game built with Tkinter that allows users to guess whether displayed cat images are real or generated by the GAN model.As mentioned before on average, the model can trick users 1 out of every 7 times with fake images, showcasing its effectiveness.
- **flip_images.py**: A utility script used for data augmentation by flipping images horizontally. This helps in training the GAN more effectively by increasing the variability in the training data.
- **understanding_conv_layers.py**: This script provides insights into the workings of Conv2DTranspose layers used in the GAN's generator, helping to explain how the model constructs images from learned patterns. This is more for your own interest or understanding if you are looking to understand how the model works a bit more.

## Requirements

The project is developed using TensorFlow and relies on specific versions of CUDA and cuDNN for GPU acceleration:

- cudnn=8.1.0.77-h3e0f4f4_0
- cudatoolkit=11.2.2-h933977f_10

A requirements.txt file is included in the repository, detailing all necessary Python packages. Install the dependencies using:

```bash
pip install -r requirements.txt
```

**Note:** Ensure that your environment meets the CUDA and cuDNN version requirements for optimal performance.

## GPU Specifications

The model was trained and tested on an NVIDIA GeForce GTX 1650 Ti with the following specifications:

- CUDA Cores: 1024
- Graphics Boost Clock: 1485 MHz
- Memory Data Rate: 12.00 Gbps
- Memory Interface: 128-bit
- Memory Bandwidth: 192.03 GB/s
- Total Available Graphics Memory: 12160 MB
- Dedicated Video Memory: 4096 MB GDDR6

**Note: A GPU is not necessary for training but it will help running the model due to computational requirements.**

## Getting Started

To train the GAN model, run python cats_training.py, if you have issues running the code due or if your GPU is not being detected try running the "run_training_with_GPU.bat" file and update the file locations in the file using a text editor

To test your ability to distinguish between real and generated images, play the interactive game by running python human_model_tester_game.py. Once again python can struggle to detect your GPU so if you run into issues try running "run_test_with_GPU.bat" and update the file first using a text editor.

# How the GAN Model Works

The Generative Adversarial Network (GAN) developed in this project is a system designed to generate 64x64 pixel cat images that are similar to real cat photos, the model architecture and training methodology incorporate techniques in deep learning to achieve this goal.

## Components of the GAN

### Generator
The generator is a neural network that starts with a latent noise vector—essentially a random seed—and transforms this seed into an image through a series of deconvolutional (Conv2DTranspose) layers. Each layer incrementally increases the resolution and complexity of the image, starting from simple patterns and textures to more detailed features resembling parts of cats. The generator's architecture is designed to efficiently map the latent space to the space of real cat images, utilizing techniques such as batch normalization and LeakyReLU activations to stabilize training and promote the flow of gradients.

### Discriminator
The discriminator acts as a critical evaluator of images, distinguishing between real images drawn from the training dataset and fake images produced by the generator. It mirrors the architecture of a typical convolutional neural network (CNN), gradually down-sampling the input image to extract features and ultimately producing a binary classification. Unlike traditional CNNs, the discriminator in this GAN setup does not end with a softmax layer; instead, it outputs a single value representing the authenticity of the input image, with the help of a sigmoid function applied at the end to interpret this value as the probability of the image being real.

### Generator's Up-sampling Mechanism

In the generator component of the GAN, the Conv2DTranspose layers serve as the backbone for up-sampling the input from a lower resolution to a higher one. Starting from an initial 8x8 representation, these layers methodically increase the resolution through a series of steps:

- From 8x8 to 16x16: The first Conv2DTranspose layer takes the 8x8 input and doubles its dimensions to 16x16, expanding the feature map while introducing finer details.
- Progressing to 32x32 and finally 64x64: Subsequent Conv2DTranspose layers continue this trend, each time doubling the resolution until reaching the final size of 64x64 pixels. This step-wise enlargement allows the network to incrementally refine the generated image, adding complexity and depth at each stage.

Here is an example of how we transition from an 8x8 to a 16x16 resolution using Conv2DTranspose layers. Each matrix entry in the input layer is multipled by the kernel, the result of this is summed to a given area in the output matrix. This output area is determined by the kernel size and the padding used, below we use a 5x5 kernel and set the padding to "same", this resembles the layers in the GAN I have trained in the code.

![GAN Up-sampling Example Input and Kernal](https://github.com/ronang101/Cat-GAN/blob/main/convolution_examples/Input_and_kernal.png)

![GAN Up-sampling Example Gif](https://github.com/ronang101/Cat-GAN/blob/main/convolution_examples/transposed_convolution.gif)

In the **understanding_conv_layers.py** you can use your own input and kernal matrices in order to create your own gif if this can help with understanding how the layers work.

### Discriminator's Down-sampling Mechanism

Conversely, the discriminator performs the opposite operation. It starts with the high-resolution input (64x64 pixels) and applies convolutional layers to systematically reduce the image size, mirroring the generator's process in reverse. This down-sampling helps in extracting pivotal features from the images to assess their authenticity effectively.

## Training Dynamics

The training of this GAN model is an iterative process of adjustment and counter-adjustment between the generator and discriminator. Initially, the generator produces images that are easily distinguishable from real images, allowing the discriminator to classify them with high accuracy. However, as training progresses:

### Generator Learning
The generator receives feedback from the discriminator's classifications, using this information to adjust its parameters and improve the realism of its generated images. It learns to focus on details that make the images more convincing, such as fur texture, eye brightness, and natural poses of cats.

### Discriminator Refinement
Concurrently, the discriminator fine-tunes its ability to detect subtle cues that differentiate real images from fake ones. It learns from both correctly and incorrectly classified examples, enhancing its analytical precision.

## Competitive Learning

This learning process is inherently competitive. The generator aims to produce images that are indistinguishable from real images, "fooling" the discriminator, while the discriminator strives to become infallible in its classifications. This competition drives the continuous improvement of both components, leading to the generation of highly realistic images.

## Learning and Adaptation

### Early Training
In the initial phases, the generated images may bear little resemblance to actual cats (in fact it looks like nothing at the start, sometimes it can look like a horror show), showcasing basic forms and colors without clear structures.

### Progressive Improvement
As training progresses, visible improvements can be observed. The generator starts creating images with recognizable cat features, including faces, eyes, and fur patterns. This evolution can be seen in the training_images directory, where images from all epochs are stored, illustrating the gradual enhancement in quality and realism.

### Final Stages
In the later stages of training, the generated images become increasingly difficult to distinguish from real cat photos, achieving the project's goal. Some images may still present artifacts or unrealistic elements, but many will pass as genuine cat images to the untrained eye. I will note the model I have created needs further training, but it is at a point where sometimes it can trick you as mentioned above.

This detailed explanation underscores the complex interplay between the generator and discriminator within the GAN framework, highlighting the nuances of training such a model to produce realistic images. The project serves as a practical exploration into the capabilities and challenges of working with GANs, providing valuable insights into deep learning techniques and model optimization.

## Usage and Experimentation

This project is open for anyone interested in deep learning, GANs, or image generation. Feel free to use it for training, model experimentation, or as a basis for your projects. Once again please note a GPU is not necessary but it will help with training and effectively running the model due to computational requirements

**Note: Unfortunately due to github upload limits I cannot upload the current checkpoint of the model as it is too large but I have left the check point folder in to show you where your checkpoints will go if you train your own model.**

